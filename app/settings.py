# -*- coding: utf-8 -*-
import os
import sys
from pathlib import Path
from typing import Literal

# === å¼•å…¥æ‰€éœ€åº“ ===
from hcaptcha_challenger.agent import AgentConfig
from pydantic import Field, SecretStr
from pydantic_settings import SettingsConfigDict
from loguru import logger

# --- æ ¸å¿ƒè·¯å¾„å®šä¹‰ ---
PROJECT_ROOT = Path(__file__).parent
VOLUMES_DIR = PROJECT_ROOT.joinpath("volumes")
LOG_DIR = VOLUMES_DIR.joinpath("logs")
USER_DATA_DIR = VOLUMES_DIR.joinpath("user_data")
RUNTIME_DIR = VOLUMES_DIR.joinpath("runtime")
SCREENSHOTS_DIR = VOLUMES_DIR.joinpath("screenshots")
RECORD_DIR = VOLUMES_DIR.joinpath("record")
HCAPTCHA_DIR = VOLUMES_DIR.joinpath("hcaptcha")

# === é…ç½®ç±»å®šä¹‰ ===
class EpicSettings(AgentConfig):
    model_config = SettingsConfigDict(env_file=".env", env_ignore_empty=True, extra="ignore")

    # [åŸºç¡€é…ç½®] API Key å»ºè®®ä½¿ç”¨ SecretStr ç±»å‹
    GEMINI_API_KEY: SecretStr | None = Field(
        default_factory=lambda: os.getenv("GEMINI_API_KEY"),
        description="LLM çš„ API Keyï¼ˆGemini å®˜æ–¹ / OpenAI å…¼å®¹å‡å¯ï¼‰",
    )
    
    GEMINI_BASE_URL: str = Field(
        default=os.getenv("GEMINI_BASE_URL", "https://generativelanguage.googleapis.com"),
        description="LLM Base URLï¼ˆå…¼å®¹æ—§å˜é‡ï¼›ä¸ä¼šè¢«ä»£ç ç§è‡ªæ”¹å†™ï¼‰",
    )
    
    GEMINI_MODEL: str = Field(
        default=os.getenv("GEMINI_MODEL", "gemini-2.5-pro"),
        description="æ¨¡å‹åç§°",
    )

    # ==========================================================
    # å…³é”®ï¼šè®©â€œç”¨æˆ·å¡«ä»€ä¹ˆæ¨¡å‹å°±ç”¨ä»€ä¹ˆæ¨¡å‹â€ï¼ˆä¸é™åˆ¶æ¨¡å‹åï¼‰
    # - hcaptcha-challenger ä¸Šæ¸¸å¯¹è¿™äº›å­—æ®µåšäº† Literal ç™½åå•ç±»å‹
    # - è¿™é‡Œå¼ºåˆ¶è¦†ç›–ä¸º strï¼Œå¹¶é»˜è®¤ç»Ÿä¸€ä½¿ç”¨ GEMINI_MODEL
    # - å¦‚éœ€å•ç‹¬å¾®è°ƒï¼Œä¹Ÿå¯åˆ†åˆ«è®¾ç½®åŒåç¯å¢ƒå˜é‡è¦†ç›–
    # ==========================================================
    CHALLENGE_CLASSIFIER_MODEL: str = Field(
        default_factory=lambda: os.getenv("CHALLENGE_CLASSIFIER_MODEL")
        or os.getenv("GEMINI_MODEL", "gemini-2.5-pro"),
        description="éªŒè¯ç ä»»åŠ¡åˆ†ç±»æ¨¡å‹ï¼ˆé»˜è®¤è·Ÿéš GEMINI_MODELï¼Œå¯ä»»æ„å­—ç¬¦ä¸²ï¼‰",
    )
    IMAGE_CLASSIFIER_MODEL: str = Field(
        default_factory=lambda: os.getenv("IMAGE_CLASSIFIER_MODEL")
        or os.getenv("GEMINI_MODEL", "gemini-2.5-pro"),
        description="ä¹å®«æ ¼å›¾åƒåˆ†ç±»æ¨¡å‹ï¼ˆé»˜è®¤è·Ÿéš GEMINI_MODELï¼Œå¯ä»»æ„å­—ç¬¦ä¸²ï¼‰",
    )
    SPATIAL_POINT_REASONER_MODEL: str = Field(
        default_factory=lambda: os.getenv("SPATIAL_POINT_REASONER_MODEL")
        or os.getenv("GEMINI_MODEL", "gemini-2.5-pro"),
        description="ç‚¹é€‰/æ¡†é€‰æ¨ç†æ¨¡å‹ï¼ˆé»˜è®¤è·Ÿéš GEMINI_MODELï¼Œå¯ä»»æ„å­—ç¬¦ä¸²ï¼‰",
    )
    SPATIAL_PATH_REASONER_MODEL: str = Field(
        default_factory=lambda: os.getenv("SPATIAL_PATH_REASONER_MODEL")
        or os.getenv("GEMINI_MODEL", "gemini-2.5-pro"),
        description="æ‹–æ‹½è·¯å¾„æ¨ç†æ¨¡å‹ï¼ˆé»˜è®¤è·Ÿéš GEMINI_MODELï¼Œå¯ä»»æ„å­—ç¬¦ä¸²ï¼‰",
    )

    # ================================
    # LLM è°ƒç”¨å±‚ï¼ˆç”¨æˆ·å¯é…ç½®ï¼‰
    # ================================
    LLM_MODE: Literal["openai", "gemini_native", "gemini_openai"] = Field(
        default=os.getenv("LLM_MODE", "gemini_native"),
        description="LLM è°ƒç”¨æ¨¡å¼ï¼šopenai / gemini_native / gemini_openai",
    )

    # æ³¨æ„ï¼šä¼˜å…ˆä½¿ç”¨ LLM_BASE_URLï¼›æœªæä¾›æ—¶å‘ä¸‹å…¼å®¹ GEMINI_BASE_URL
    LLM_BASE_URL: str = Field(
        default=os.getenv("LLM_BASE_URL", "")
        or os.getenv("GEMINI_BASE_URL", "https://generativelanguage.googleapis.com"),
        description="LLM Base URLï¼ˆä¸¥ç¦ä»£ç æ“…è‡ªæ”¹å†™/é‡å†™ï¼‰ã€‚",
    )

    # æ˜¯å¦åœ¨å¯åŠ¨æ—¶æ‰§è¡Œ LLM preflightï¼ˆdeploy.py ä¸­è°ƒç”¨ï¼‰
    LLM_PREFLIGHT: bool = Field(
        default=os.getenv("LLM_PREFLIGHT", "true").lower() in {"1", "true", "yes", "y", "on"},
        description="å¯åŠ¨æ—¶æ‰§è¡Œ LLM preflight/healthcheckï¼ˆtrue/falseï¼‰",
    )

    EPIC_EMAIL: str = Field(default_factory=lambda: os.getenv("EPIC_EMAIL"))
    EPIC_PASSWORD: SecretStr = Field(default_factory=lambda: os.getenv("EPIC_PASSWORD"))
    DISABLE_BEZIER_TRAJECTORY: bool = Field(default=True)

    # ================================
    # è¶…æ—¶ï¼ˆå…è®¸é€šè¿‡ç¯å¢ƒå˜é‡è¦†ç›–ï¼‰
    # - ä¸Šæ¸¸é»˜è®¤ RESPONSE_TIMEOUT=30 åœ¨ Actions ç¯å¢ƒå®¹æ˜“ä¸å¤Ÿ
    # ================================
    EXECUTION_TIMEOUT: float = Field(
        default=float(os.getenv("EXECUTION_TIMEOUT", "180")),
        description="éªŒè¯ç æ•´ä½“æ‰§è¡Œè¶…æ—¶ï¼ˆç§’ï¼‰ï¼Œé»˜è®¤ 180ï¼Œå¯ç”¨ env è¦†ç›–",
    )
    RESPONSE_TIMEOUT: float = Field(
        default=float(os.getenv("RESPONSE_TIMEOUT", "90")),
        description="ç­‰å¾…éªŒè¯ç æœåŠ¡å“åº”è¶…æ—¶ï¼ˆç§’ï¼‰ï¼Œé»˜è®¤ 90ï¼Œå¯ç”¨ env è¦†ç›–",
    )

    cache_dir: Path = HCAPTCHA_DIR.joinpath(".cache")
    challenge_dir: Path = HCAPTCHA_DIR.joinpath(".challenge")
    captcha_response_dir: Path = HCAPTCHA_DIR.joinpath(".captcha")

    ENABLE_APSCHEDULER: bool = Field(default=True)
    TASK_TIMEOUT_SECONDS: int = Field(default=900)
    REDIS_URL: str = Field(default="redis://redis:6379/0")
    CELERY_WORKER_CONCURRENCY: int = Field(default=1)
    CELERY_TASK_TIME_LIMIT: int = Field(default=1200)
    CELERY_TASK_SOFT_TIME_LIMIT: int = Field(default=900)

    @property
    def user_data_dir(self) -> Path:
        target_ = USER_DATA_DIR.joinpath(self.EPIC_EMAIL)
        target_.mkdir(parents=True, exist_ok=True)
        return target_

settings = EpicSettings()
settings.ignore_request_questions = ["Please drag the crossing to complete the lines"]

def _apply_llm_provider_patch() -> None:
    """
    å°† hcaptcha-challenger é»˜è®¤çš„ GeminiProvider æ›¿æ¢ä¸ºæœ¬é¡¹ç›®çš„é€šç”¨ LLM Providerã€‚

    ç›®æ ‡ï¼š
    - æ”¯æŒä»»æ„ base_urlï¼ˆä¸¥ç¦ä»£ç æ“…è‡ªæ”¹å†™/é‡å†™ï¼‰
    - æ”¯æŒ OpenAI å…¼å®¹ & Gemini å®˜æ–¹ï¼ˆnative / openaiï¼‰ä¸‰ç§æ¨¡å¼
    """
    if not settings.GEMINI_API_KEY:
        return

    try:
        from hcaptcha_challenger.tools.internal.base import Reasoner
        from llm.provider import HcaptchaLLMProvider

        def _create_default_provider(self):  # type: ignore[no-redef]
            return HcaptchaLLMProvider(
                api_key=str(self._api_key),
                model=str(self._model) if self._model else "",
                mode=settings.LLM_MODE,
                base_url=settings.LLM_BASE_URL,
            )

        Reasoner._create_default_provider = _create_default_provider  # type: ignore[method-assign]
        logger.info(
            "ğŸš€ LLM Provider è¡¥ä¸å·²åº”ç”¨ | mode: {} | base_url: {}",
            settings.LLM_MODE,
            settings.LLM_BASE_URL,
        )
    except Exception as e:
        logger.error(f"âŒ LLM Provider è¡¥ä¸åŠ è½½å¤±è´¥: {e}")


_apply_llm_provider_patch()
